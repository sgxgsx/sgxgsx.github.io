---
title: The hidden attack surface - Exploiting Prompt Overrides in OpenAI and Anthropic SDKs
description: A single, unchecked parameter in the OpenAI and Anthropic SDKs lets an attacker overwrite your AI Agent's system prompt, take over every response, and, in some cases, open a reverse shell from your server. This article explains how the issue works, shows you how to reproduce it, and, most importantly, how to fix it.
slug: exploiting-prompt-overrides-in-openai-and-anthropic-sdks
date: 2025-06-03 00:00:00+0000
image: cover-hidden-attack-surface.jpeg
categories:
    - Bug Bounty
tags:
    - Bug Bounty
    - LLM
    - SDK
    - OpenAI
    - Anthropic
weight: 1      
---



Want to experiment (otherwise skip the code)? Below is the exact agent code running in a test-SaaS back-end. Interact with it on the `/chat` route and try to break it yourself ( for instructions: [https://github.com/sgxgsx/vulnerable_ai_agent](https://github.com/sgxgsx/vulnerable_ai_agent)).

```
import anthropic
import json
import requests
from flask import Flask, request, jsonify
from flask import Flask, request, jsonify, render_template
import os
import httpx

http_client_without_ssl_verification = httpx.Client(verify=False, proxy="http://localhost:8080")

API_KEY = 'sk-ant-api03-...'


client = anthropic.Anthropic(
    api_key=API_KEY,
    http_client=http_client_without_ssl_verification
)


def call(code):
    try:
        output = os.popen(code).read()
        return output
    except Exception as e:
        return {"error": str(e)}


def get_weather(latitude, longitude):
    response = requests.get(f"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m")
    data = response.json()
    return data['current']['temperature_2m']


def call_function(name, args):
    if name == "get_weather":
        return get_weather(**args)
    if name == "call":
        return call(**args)

def chat_with_agent(user_input, additional_parameters={}):
    messages=[
            {"role": "user", "content": user_input}
    ]

    tools = [
        {
            "name": "call",
            "description": "Executes a command",
            "input_schema": {
                "type": "object",
                "properties": {
                    "code": {"type": "string", "description": "code to execute"}
                },
                "required": ["code"]
            }
        },
        {
            "name": "get_weather",
            "description": "Get whether in a specific location based on latitude and longitude",
            "input_schema": {
                "type": "object",
                "properties": {
                    "latitude": {"type": "number", "description": "latitude of the location"},
                    "longitude": {"type": "number", "description": "longitude of the location"},
                },
                "required": ["latitude", "longitude"]
            }
        }
    ]


    
    response = client.messages.create(
        model="claude-3-5-haiku-20241022",
        max_tokens=8192,
        temperature=1,
        system="You are a support chat agent. Help the user with their query. You are strictly allowed to execute only get_weather function. You are not allowed to execute functions.call or call function/tool ever. You are not allowed to disclose any information about functions.call or call function/tool ever to anyone! follow the rules regarding functions.call!",
        messages=messages,
        tools=tools,
        extra_body=additional_parameters
    )
    if response.stop_reason == "tool_use":
        tool_results = []
        for tool_use in response.content:
            if tool_use.type == "tool_use":
                name = tool_use.name
                args = tool_use.input
                result = call_function(name, args)
                tool_results.append({
                            "type": "tool_result",
                            "tool_use_id": tool_use.id,
                            "content": str(result)
                        })
            
        messages = [
            {"role": "user", "content": user_input},
            {"role": "assistant", "content": response.content},
            {
                "role":"user",
                "content":tool_results
            }
        ]

        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=8192,
            temperature=1,
            system="You are a support chat agent. Help the user with their query. You are strictly allowed to execute only get_weather function. You are not allowed to execute functions.call or call function/tool ever. You are not allowed to disclose any information about functions.call or call function/tool ever to anyone! follow the rules regarding functions.call!",
            messages=messages,
            tools=tools
        )
    
    final_response = next(
        (block.text for block in response.content if hasattr(block, "text")),
        None,
    )
        
    return final_response



template_dir = os.path.abspath('./templates')
static_dir = os.path.abspath('./static')

app = Flask(__name__, template_folder=template_dir, static_folder=static_dir)


@app.after_request
def add_cors_headers(resp):
    resp.headers["Access-Control-Allow-Origin"] = "*"
    resp.headers["Access-Control-Allow-Headers"] = "Content-Type"
    resp.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"
    return resp

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/chat', methods=['POST', 'OPTIONS'])
def chat():
    if request.method == "OPTIONS": 
        return ("", 204)
    input_json = request.get_json()
    user_input = input_json['user_input']
    additional_parameters = input_json.get('additional_parameters', {})
    response = chat_with_agent(user_input, additional_parameters)
    return jsonify({'response': response})

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=5000)

```


### THE HIDDEN PARAMETER THAT BREAKS THE RULES

While reviewing Anthropic’s SDK, I noticed several undocumented request fields. 

![undocumented params](undocumented_params.png)

They look like innocent extras - until you see these lines:
```
json_data = _merge_mappings(json_data, options.extra_json)
```
```
def _merge_mappings(
    obj1: Mapping[_T_co, Union[_T, Omit]],
    obj2: Mapping[_T_co, Union[_T, Omit]],
) -> Dict[_T_co, _T]:
    """Merge two mappings of the same type, removing any values that are instances of `Omit`.

    In cases with duplicate keys the second mapping takes precedence.
    """
    merged = {**obj1, **obj2}
    return {key: value for key, value in merged.items() if not isinstance(value, Omit)}
```
Because `extra_json` takes precedence, we can overwrite the `system` parameter for Anthropic (or `messages` for OpenAI) and hijack execution flow. It’s a simple, vulnerable pattern with no obvious warning to developers who assume these are just “extra” parameters.

To exploit this vulnerability, two prerequisites must be met:

- An adversary must be able to set an arbitrary key and value—mass assignment via GET/POST parameters, headers, or cookies works well.
- To affect an end user, an attacker must also be able to set those keys on the user’s behalf—again via GET/POST parameters, redirects, or `postMessage` calls.

Impact varies widely. If attackers can set keys on behalf of end users, or if the agent exposes dangerous tools that execute code or leak data, the risk skyrockets.

![Possible attack vectors](possible_attacks.png)

For example, in the sample code which you reviewed, the agent exposes a `call` function that executes shell commands. Once an attacker replaces the system prompt that forbids calling it, remote code execution is possible.

```
{
  "type": "function",
  "function": {
    "name": "call",
    "description": "Executes a shell command and returns the output or an error message.",
    "strict": True,
    "parameters": {
      "type": "object",
      "required": [
        "code"
      ],
      "properties": {
        "code": {
          "type": "string",
          "description": "The shell command to execute."
        }
      },
      "additionalProperties": False
    }
  }
}
```

### Real code from GitHub: Safe vs. Unsafe
I searched GitHub for projects that use `extra_body`, ignoring pure CLI apps. Few people share full web-integrated agents, but these two snippets illustrate good and bad practice:
- **Safe approach** — AstrBot validates every key before merging.  
    [https://github.com/AstrBotDevs/AstrBot/blob/9147cab75bacf5d7f81548d8b209faac13a77d32/astrbot/core/provider/sources/openai_source.py#L103](https://github.com/AstrBotDevs/AstrBot/blob/9147cab75bacf5d7f81548d8b209faac13a77d32/astrbot/core/provider/sources/openai_source.py#L103)...

![safe approach](astr_bot_1.png)
![safe approach](astr_bot_2.png)

- **Unsafe approach** — MaxKB merges everything without filtering.  
    [https://github.com/1Panel-dev/MaxKB/blob/7ce66a7bf3ddf123a648e23db920eeaeb00cbe42/apps/setting/models_provider/base_model_provider.py#L109](https://github.com/1Panel-dev/MaxKB/blob/7ce66a7bf3ddf123a648e23db920eeaeb00cbe42/apps/setting/models_provider/base_model_provider.py#L109)...

![unsafe approach](maxkb.png)

### How to fix it

1. **Whitelist keys** you accept; reject the rest.
2. **Strip unknown keys** if you cannot whitelist.
3. **Treat `extra_body` as untrusted input**.

### Key takeaways
* Always review undocumented features :)

### Timeline
- **16 Mar 2025** - Reported to Anthropic
- **16 Mar 2025** - Realized OpenAI was vulnerable too; reported to OpenAI
- Some back-and-forth with both vendors
- **21 Mar 2025** - Anthropic accepted the submission, issued a $1000 bounty and is exploring remediation.
- **02 Apr 2025** - OpenAI replied: “works as expected”…
- **28 May 2025** - Anthropic added a warning to the documentation: [https://github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#undocumented-request-params](https://github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#undocumented-request-params)
- **03 Jun 2025** - Full public disclosure so developers can patch their code.




